# ðŸ§  Tiny LLM

Fine-tune and deploy small language models â€” from your Mac to the cloud.

[![CI](https://github.com/rahuldhole/tiny-llm/actions/workflows/ci.yml/badge.svg)](https://github.com/rahuldhole/tiny-llm/actions/workflows/ci.yml)
[![Train](https://github.com/rahuldhole/tiny-llm/actions/workflows/train.yml/badge.svg)](https://github.com/rahuldhole/tiny-llm/actions/workflows/train.yml)
[![Space](https://img.shields.io/badge/ðŸ¤—-Live%20Demo-yellow)](https://huggingface.co/spaces/rahuldhole/tiny-llm-chat)
[![Model](https://img.shields.io/badge/ðŸ¤—-Model-blue)](https://huggingface.co/rahuldhole/tiny-llm-qwen-adapter)

## Architecture

```
Push data/ or configs/ â†’ GitHub Actions trains on CPU â†’ evaluates â†’ uploads adapter to HF Hub
Push app.py             â†’ GitHub Actions syncs HF Space â†’ live Gradio demo loads adapter from Hub
```

## Quick Start

> Requires [Task](https://taskfile.dev) (`brew install go-task`) and Python 3.9+

```bash
task setup        # create venv + install deps
task train        # fine-tune locally (MPS/CUDA/CPU auto-detected)
task evaluate     # run eval, output JSON results
task app          # launch Gradio GUI at localhost:7860
```

## CI/CD Pipeline

| Workflow | Trigger | What it does |
|---|---|---|
| `ci.yml` | Every push/PR | Lint + smoke test |
| `train.yml` | `data/` or `configs/` changed on main | Train â†’ Evaluate â†’ Upload model to HF Hub |
| `deploy.yml` | `app.py` changed on main | Sync Gradio app to HF Spaces |

### Setup Secrets

```bash
cp env.example .env    # fill in your HF token
task sync-secrets      # push to GitHub Actions (requires gh CLI)
```

## All Tasks

```bash
task setup         # install dependencies
task train         # fine-tune model
task evaluate      # evaluate + JSON output
task app           # Gradio GUI
task chat          # CLI chat
task lint          # ruff linting
task deploy-model  # upload adapter to HF Hub
task deploy-space  # sync app to HF Spaces
task deploy        # both
task sync-secrets  # push .env â†’ GitHub secrets
```

## Project Structure

```
tiny-llm/
â”œâ”€â”€ .github/workflows/   # CI/CD pipelines
â”œâ”€â”€ configs/             # training hyperparameters (YAML)
â”œâ”€â”€ data/                # training data (JSONL)
â”œâ”€â”€ docs/                # guides and documentation
â”œâ”€â”€ src/                 # source code
â”‚   â”œâ”€â”€ train.py         # config-driven fine-tuning
â”‚   â”œâ”€â”€ evaluate.py      # structured eval with JSON output
â”‚   â”œâ”€â”€ inference.py     # CLI chat
â”‚   â””â”€â”€ app.py           # local Gradio app
â”œâ”€â”€ app.py               # HF Spaces entrypoint
â”œâ”€â”€ Taskfile.yaml        # task runner
â””â”€â”€ requirements.txt     # training deps
```

## Requirements

- Python 3.9+
- 8GB+ RAM
- Mac (MPS), Linux (CUDA), or CPU
- Model: [Qwen/Qwen2.5-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct)

## Docs

- [Environment Setup](docs/environment_setup.md)
- [Inference](docs/01_inference.md)
- [Data Preparation](docs/02_data.md)
- [Fine-tuning](docs/03_finetuning.md)
- [Evaluation](docs/04_evaluation.md)
- [CI/CD Pipeline](docs/05_cicd.md)
